Thread - A lightweight unit of execution within a process allows to perform multiple tasks concurrently
Process - An independent program with its own memory space

Memory Management
Processes have separate memory space
Threads within the same process share memory, allowing efficient data sharing but requiring careful synchronization
Resource Consumption
Creating a new process is computationally expensive and requires significant system resources
Threads are lightweight and can be created and destroyed quickly with minimum overhead
Communication
Processes communicate through complex mechanisms
Threads can communicate directly by sharing memory

Creating Threads -> ThreadsDemo.ThreadCreation
extending the Thread class
implementing Runnable interface

Callable -> ThreadsDemo.CallableDemo
unlike Runnable, Callable returns results and throws checked exceptions. Callable works with Future objects to retrieve
results after task completion. It works with ExecutorService framework rather than directly extending Thread

Runnable vs Callable
Runnable cannot return result and throw exceptions while Callable can
run() should be implemented for Runnable, call() should be implemented for Callable
Runnable works with Thread whereas Callable works with ExecutorService and Future

start() vs run() -> ThreadsDemo.RunVsStart
directly calling run will not create a new thread, it will execute in the current thread
also we cannot thread.start() more than once

Thread safety
refers to the code that functions correctly during simultaneous execution by multiple threads
it can be achieved through
synchronization
immutable objects
concurrent collections
atomic variables

sleep() vs wait()
sleep() causes the current thread to pause for a specified time without realising locks
wait() causes the current thread wait until another thread invokes notify() or notifyAll() on the same object, and it
releases the lock on the object

ThreadPools - ThreadsDemo.FixedThreadPoolDemo
are managed collection of reusable threads designed to execute tasks concurrently
Explanation from example
Executors.newFixedThreadPool(3) creates a pool with 3 reusable threads.
Five tasks are submitted. Since only 3 threads exist, the first 3 tasks start immediately.
As tasks complete, the available threads pick up the remaining tasks.
Threads are reused, avoiding the overhead of creating new threads for each task. After task completion, the thread
returns to the pool (RUNNABLE state waiting for next task)
The execution order may vary based on CPU scheduling.
Pool Shutdown: During shutdown, threads complete their current tasks and are eventually terminated.

Executors.newCachedThreadPool()
Threads are created dynamically as needed, avoiding delays due to waiting.

ThreadPoolExecutor
It provides a thread pool implementation for executing tasks concurrently.
It’s the backbone of most thread pools created via Executors factory methods (like Executors.newFixedThreadPool()).
ThreadsDemo.ThreadPoolExecutorDemo
Core size = 2 → first 2 tasks get threads immediately.
Queue size = 2 → next 2 tasks go into queue.
Max size = 4 → 2 more tasks can start new threads.
If more tasks are submitted → rejected

Core Executor Interfaces and Classes
Executor: The base interface defining task execution
Executor is the simplest form—just defines a execute(Runnable) method. You provide a task, and it decides how to run it
ExecutorService: Extends Executor with lifecycle management
ExecutorService allows advanced task handling with submit(), invokeAll(), shutdown(), and Future results for return
values and tracking task completion. submit(Runnable), submit(Callable)
ScheduledExecutorService: Adds task scheduling capabilities -> ThreadsDemo.ScheduledExecutorDemo
Allows you to schedule tasks to run after a delay or at a fixed rate—ideal for repeated jobs like health checks or
polling. schedule(Runnable/Callable, delay, TimeUnits)
Executors: Factory class for creating executor instances

Task Submission Methods
execute(Runnable) Task runs asynchronously. No result is expected or tracked.
Future<?> submit(Runnable/Callable) Returns a Future. You can block and get the result using future.get().
invokeAll(Collection<? extends Callable<T>> tasks) Runs all tasks in parallel. Waits until all finish. You get a list of
Futures.

Lifecycle Management Methods
ThreadsDemo.ShutDownVsShutDownNow
shutdown - graceful shutdown, no new tasks are accepted, but already submitted tasks (in queue + running) will still
complete.
shutdownNoe - Immediate shutdown, Attempts to stop all actively executing tasks by interrupting threads. Discards all
tasks waiting in the queue (returns them as a List<Runnable>).

What happens if you don't explicitly shut down an ExecutorService?
The executor's threads will continue running, preventing the JVM from shutting down normally (unless they're daemon
threads). This can cause memory leaks and resource exhaustion. Always call shutdown() or shutdownNow() when done with an
executor.

Thread Synchronization in Java
Thread synchronization is a critical concept in multithreaded programming that ensures multiple threads access shared
resources in a controlled manner. Proper synchronization prevents data corruption, race conditions, and ensures thread
safety in a concurrent environment.
The synchronized keyword is used to control access to critical sections of code so that only one thread can execute the
synchronized code at a time. This ensures that shared mutable data is not corrupted by concurrent modifications

Synchronized Method -> ThreadsDemo.SynchronizedMethodDemo
When you declare an entire method as synchronized, the lock is acquired on the object instance
(or on the Class object for static methods) before the method is executed and released after it finishes
This is useful when the whole method represents a critical section where no concurrent execution is desired. It is
straightforward and reduces the chance of forgetting to protect part of the code

Synchronized Block -> ThreadsDemo.SynchronizedBlockDemo
A synchronized block allows you to specify a particular block of code to be synchronized, along with the object on which
to acquire the lock
The primary reason to choose a synchronized block over a synchronized method is when you have additional work in the
method that doesn’t need to be synchronized. This allows concurrent threads to execute the non-critical sections without
waiting for the lock

volatile
When a variable is declared volatile, its value is always read from and written to the main memory instead of a
thread’s local cache.
This means changes made by one thread are immediately visible to others.
It doesn't guarantee Atomicity. Used in flags

Atomic Variables -> ThreadsDemo.AtomicCounterDemo
in Java—found in the java.util.concurrent.atomic package—are designed to support lock-free, thread-safe
operations on single variables. You should use atomic variables when you need to perform simple operations
(like incrementing, decrementing, or updating) on shared variables in a multithreaded environment. They are especially
useful when the overhead of locking is undesirable and when the logic remains limited to single-step atomic operations

Thread Communication in Java -> ThreadsDemo.ProducerConsumer
is a fundamental concept in concurrent programming that allows multiple threads to coordinate and share data effectively
wait(): When a thread calls the wait() method on an object, it releases the monitor it holds on that object and goes
into a waiting state. For example, a consumer thread might wait for a producer to produce an item.
notify(): The notify() method wakes up a single thread that is waiting on the object’s monitor. If more than one thread
is waiting, the scheduler chooses one arbitrarily
notifyAll(): The notifyAll() method wakes up all threads that are waiting on the object’s monitor.

Concurrent Collections
ConcurrentHashMap - Thread safe implementation of HashMap
CopyOnWriteArrayList - Thread safe implementation of ArrayList

Compare and Swap
CAS is a low-level atomic operation used to implement synchronization in multithreaded programs without using locks.
It’s widely used in lock-free and non-blocking algorithms.
CAS works by comparing a memory value with an expected value, and if they match, swapping it with a new value — all as a
single atomic CPU instruction.
https://howtodoinjava.com/java/multi-threading/compare-and-swap-cas-algorithm/

Future and Completable Future in Java: Asynchronous Programming Essentials
The Future interface, introduced in Java 5, represents the result of an asynchronous computation. It provides a way to
check if the computation is complete, wait for its completion, and retrieve the result.
Key Features of Future -> ThreadsDemo.FutureDemo
submit() starts the task asynchronously.
future.get() blocks until the task finishes and returns the result.
get(long timeout, TimeUnit unit) if you want to avoid indefinite blocking as :
future.get() blocks the current thread until the task completes — this could take forever if the task hangs.
future.get(timeout, unit) adds a maximum wait time.
If the result isn’t ready in that time, it throws a TimeoutException, and your thread can recover gracefully instead of
hanging forever.
isDone() tells if the task is finished.
Limitations of Future in Java
Future does not support chaining multiple tasks together. You cannot specify a dependent task that should execute once
the Future completes, making it difficult to manage sequential asynchronous computations.
There is no built-in mechanism to handle exceptions in the Future. If an exception occurs during execution, you must
manually catch it using get(), which can make error handling cumbersome.

CompletableFuture -> ThreadsDemo.CompletableFutureDemo
CompletableFuture, introduced in Java 8, extends the Future interface and implements the CompletionStage interface. It
addresses the limitations of Future and provides a rich set of methods for composing, combining, and handling
asynchronous computations.
Combining CompletableFutures -> ThreadsDemo.CompletableFutureCombiningDemo
In situations where multiple asynchronous tasks are running in parallel, CompletableFuture makes it easy to combine
their results using thenCombine. Additionally, you can wait for all tasks to complete or get the first completed result
using allOf and anyOf.
Exception Handling -> ThreadsDemo.CompletableFutureExceptionHandling
CompletableFuture provides robust mechanisms for handling exceptions during asynchronous tasks. Use exceptionally to
recover from errors or handle to manage both success and failure scenarios.

Future vs CompletableFuture
Result Retrieval os blocking in Future, blocking and non-blocking in CompletableFuture
Exception Handling is limited in Future, Robust in CompletableFuture
Combining results is not possible in Future
Executor is required in Future, CompletableFuture uses ForkJoinPool by default